{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf494926748d4c0eb3ee83d092fa3732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce88f383b00e4f24b3fa62a67cb7a807",
              "IPY_MODEL_b2efed0c25474c1ab6740fffca020f88",
              "IPY_MODEL_6aa3b317969b4396ac46e6693ea62e8f"
            ],
            "layout": "IPY_MODEL_9aaa545976ea4cdaab1cb5b9ce8b3fff"
          }
        },
        "ce88f383b00e4f24b3fa62a67cb7a807": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_936d983ae63a477dbfb72946ea497602",
            "placeholder": "​",
            "style": "IPY_MODEL_738a3e2ae35e437ba1aa34714bd779c1",
            "value": "README.md: 100%"
          }
        },
        "b2efed0c25474c1ab6740fffca020f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa62a59fa568407a83ff7734709c2226",
            "max": 30343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0f5c8c09c62424b9e8a8f376a7ebdcd",
            "value": 30343
          }
        },
        "6aa3b317969b4396ac46e6693ea62e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9d004ef3ed54f4e87712db0c1a30b61",
            "placeholder": "​",
            "style": "IPY_MODEL_a0c8da8e00e142fa87890122527b76c3",
            "value": " 30.3k/30.3k [00:00&lt;00:00, 1.65MB/s]"
          }
        },
        "9aaa545976ea4cdaab1cb5b9ce8b3fff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "936d983ae63a477dbfb72946ea497602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738a3e2ae35e437ba1aa34714bd779c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa62a59fa568407a83ff7734709c2226": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0f5c8c09c62424b9e8a8f376a7ebdcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9d004ef3ed54f4e87712db0c1a30b61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c8da8e00e142fa87890122527b76c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "272dbb310fcb44dca22a54d44ee7ae40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3e189f7bf94488e98c7b3088e9e4e5a",
              "IPY_MODEL_4e7eb1ac85394487959bc31674d9b3bc",
              "IPY_MODEL_245e4cd8b39947b3a431e30dc97afc28"
            ],
            "layout": "IPY_MODEL_1e2d8d8ef6954fd09da864fb8f7c75c8"
          }
        },
        "c3e189f7bf94488e98c7b3088e9e4e5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76a051430da44a24aee3d3002744a367",
            "placeholder": "​",
            "style": "IPY_MODEL_4af8767d70f3405a86f6ac79990d9043",
            "value": "Amazon-Reviews-2023.py: 100%"
          }
        },
        "4e7eb1ac85394487959bc31674d9b3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81d70e7c805746d7903bd2356411ad10",
            "max": 39620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f2f568c383740899beed20659d17ac4",
            "value": 39620
          }
        },
        "245e4cd8b39947b3a431e30dc97afc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d9b3179bbba43b9b85b13cebb928f07",
            "placeholder": "​",
            "style": "IPY_MODEL_d71a1a67bef94f18aad3df08681ab103",
            "value": " 39.6k/39.6k [00:00&lt;00:00, 2.58MB/s]"
          }
        },
        "1e2d8d8ef6954fd09da864fb8f7c75c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a051430da44a24aee3d3002744a367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af8767d70f3405a86f6ac79990d9043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81d70e7c805746d7903bd2356411ad10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2f568c383740899beed20659d17ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d9b3179bbba43b9b85b13cebb928f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71a1a67bef94f18aad3df08681ab103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfwwhGA9EPsg",
        "outputId": "8549b1fb-3b00-4851-9a75-e3f5f8791de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import random as random\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ],
      "metadata": {
        "id": "jkAJjRM8EQr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset with streaming enabled\n",
        "dataset = load_dataset(\n",
        "    \"McAuley-Lab/Amazon-Reviews-2023\",\n",
        "    \"raw_review_Home_and_Kitchen\",\n",
        "    streaming=True,  # Enable streaming to handle large data\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "subset = []\n",
        "\n",
        "for count, row in enumerate(dataset[\"full\"]):\n",
        "    subset.append(row)\n",
        "    if count + 1 == 100000:\n",
        "        break\n",
        "\n",
        "# Convert the list of dictionaries to a pandas DataFrame\n",
        "df = pd.DataFrame(subset)\n",
        "\n",
        "# Define the path to save the CSV in Google Drive\n",
        "output_path = \"/content/drive/My Drive/home_reviews_100000.csv\"\n",
        "\n",
        "# Save the DataFrame to CSV\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"CSV file saved at: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244,
          "referenced_widgets": [
            "bf494926748d4c0eb3ee83d092fa3732",
            "ce88f383b00e4f24b3fa62a67cb7a807",
            "b2efed0c25474c1ab6740fffca020f88",
            "6aa3b317969b4396ac46e6693ea62e8f",
            "9aaa545976ea4cdaab1cb5b9ce8b3fff",
            "936d983ae63a477dbfb72946ea497602",
            "738a3e2ae35e437ba1aa34714bd779c1",
            "fa62a59fa568407a83ff7734709c2226",
            "f0f5c8c09c62424b9e8a8f376a7ebdcd",
            "e9d004ef3ed54f4e87712db0c1a30b61",
            "a0c8da8e00e142fa87890122527b76c3",
            "272dbb310fcb44dca22a54d44ee7ae40",
            "c3e189f7bf94488e98c7b3088e9e4e5a",
            "4e7eb1ac85394487959bc31674d9b3bc",
            "245e4cd8b39947b3a431e30dc97afc28",
            "1e2d8d8ef6954fd09da864fb8f7c75c8",
            "76a051430da44a24aee3d3002744a367",
            "4af8767d70f3405a86f6ac79990d9043",
            "81d70e7c805746d7903bd2356411ad10",
            "2f2f568c383740899beed20659d17ac4",
            "0d9b3179bbba43b9b85b13cebb928f07",
            "d71a1a67bef94f18aad3df08681ab103"
          ]
        },
        "id": "yInp7mgQEVOx",
        "outputId": "b2ffaf1f-d6b6-46eb-db56-93bf6c57ca88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/30.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf494926748d4c0eb3ee83d092fa3732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Amazon-Reviews-2023.py:   0%|          | 0.00/39.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "272dbb310fcb44dca22a54d44ee7ae40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file saved at: /content/drive/My Drive/home_reviews_100000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/home_reviews_100000.csv\")\n",
        "print(\"columns:\", df.columns.tolist())\n",
        "# make sure you see ['user_id','asin','rating', …]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VK1k9tnEfVa",
        "outputId": "3c09eaa1-d3c8-4a75-d782-f0452f4c68fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "columns: ['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id', 'timestamp', 'helpful_vote', 'verified_purchase']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.columns)\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tRm1e6WF7Wh",
        "outputId": "3e4b397d-36d0-443b-9dc7-db5fa57b140f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   rating                                            title  \\\n",
            "0     1.0   Received Used & scratched item! Purchased new!   \n",
            "1     5.0         Excellent for moving & storage & floods!   \n",
            "2     2.0  Lid very loose- needs a gasket imo. Small base.   \n",
            "3     5.0                              Best purchase ever!   \n",
            "4     5.0                              Excellent for yarn!   \n",
            "\n",
            "                                                text  \\\n",
            "0  Livid.  Once again received an obviously used ...   \n",
            "1  I purchased these for multiple reasons. The ma...   \n",
            "2  [[VIDEOID:c87e962bc893a948856b0f1b285ce6cc]] I...   \n",
            "3  If you live at a higher elevation like me (5k ...   \n",
            "4  I use these to store yarn. They easily hold 12...   \n",
            "\n",
            "                                              images        asin parent_asin  \\\n",
            "0                                                 []  B007WQ9YNO  B09XWYG6X1   \n",
            "1                                                 []  B09H2VJW6K  B0BXDLF8TW   \n",
            "2  [{'small_image_url': 'https://m.media-amazon.c...  B07RL297VR  B09G2PW8ZG   \n",
            "3  [{'small_image_url': 'https://m.media-amazon.c...  B09CQF4SWV  B08CSZDXZY   \n",
            "4  [{'small_image_url': 'https://images-na.ssl-im...  B003U6A3EY  B0C6V27S6N   \n",
            "\n",
            "                        user_id      timestamp  helpful_vote  \\\n",
            "0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1677373409298             1   \n",
            "1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1672043410846             0   \n",
            "2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1653447296788             0   \n",
            "3  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1651855096178             0   \n",
            "4  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ  1589934525940             1   \n",
            "\n",
            "   verified_purchase  \n",
            "0               True  \n",
            "1               True  \n",
            "2               True  \n",
            "3               True  \n",
            "4               True  \n",
            "Index(['rating', 'title', 'text', 'images', 'asin', 'parent_asin', 'user_id',\n",
            "       'timestamp', 'helpful_vote', 'verified_purchase'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100000 entries, 0 to 99999\n",
            "Data columns (total 10 columns):\n",
            " #   Column             Non-Null Count   Dtype  \n",
            "---  ------             --------------   -----  \n",
            " 0   rating             100000 non-null  float64\n",
            " 1   title              99992 non-null   object \n",
            " 2   text               99992 non-null   object \n",
            " 3   images             100000 non-null  object \n",
            " 4   asin               100000 non-null  object \n",
            " 5   parent_asin        100000 non-null  object \n",
            " 6   user_id            100000 non-null  object \n",
            " 7   timestamp          100000 non-null  int64  \n",
            " 8   helpful_vote       100000 non-null  int64  \n",
            " 9   verified_purchase  100000 non-null  bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(6)\n",
            "memory usage: 7.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOCpGzIyGQlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 2) FILTER & SAMPLE ────────────────────────────────────────────────────────\n",
        "# only users with >5 reviews\n",
        "user_counts = df[\"user_id\"].value_counts()\n",
        "good_users  = user_counts[user_counts > 5].index\n",
        "df = df[df[\"user_id\"].isin(good_users)].copy()\n",
        "\n",
        "# sample 1,000 users (optional)\n",
        "import random\n",
        "chosen = random.sample(good_users.tolist(), 1_000)\n",
        "df = df[df[\"user_id\"].isin(chosen)].reset_index(drop=True)\n",
        "\n",
        "# ─── 3) LABEL & ENCODE ─────────────────────────────────────────────────────────\n",
        "# binary label: rating >= 4 → positive\n",
        "df[\"label\"] = (df[\"rating\"] >= 4).astype(int)\n",
        "\n",
        "# build lookup maps\n",
        "users = df[\"user_id\"].unique().tolist()\n",
        "items = df[\"asin\"   ].unique().tolist()\n",
        "user2idx = {u:i for i,u in enumerate(users, start=1)}\n",
        "item2idx = {a:i for i,a in enumerate(items, start=1)}\n",
        "\n",
        "df[\"user_idx\"] = df[\"user_id\"].map(user2idx).fillna(0).astype(int)\n",
        "df[\"item_idx\"] = df[\"asin\"   ].map(item2idx).fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "SJbqnmpSF92h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oQZpkYOhGSAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 4) SPLIT ─────────────────────────────────────────────────────────────────\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# ─── 5) DATASET ────────────────────────────────────────────────────────────────\n",
        "class FMDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.u = torch.LongTensor(df[\"user_idx\"].values)\n",
        "        self.i = torch.LongTensor(df[\"item_idx\"].values)\n",
        "        self.y = torch.FloatTensor(df[\"label\"].values)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        Xi = torch.stack([self.u[idx], self.i[idx]]).unsqueeze(1)  # [fields=2,1]\n",
        "        Xv = torch.ones_like(Xi, dtype=torch.float)               # all weights=1\n",
        "        return Xi, Xv, self.y[idx]\n",
        "\n",
        "batch_size    = 512\n",
        "train_loader  = DataLoader(FMDataset(train_df), batch_size, shuffle=True)\n",
        "val_loader    = DataLoader(FMDataset(val_df),   batch_size)\n",
        "\n",
        "n_users = len(user2idx) + 1\n",
        "n_items = len(item2idx) + 1"
      ],
      "metadata": {
        "id": "Lg_z9JlnGBZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ─── 6) DeepFM ────────────────────────────────────────────────────────────────\n",
        "class DeepFM(nn.Module):\n",
        "    def __init__(self, feature_sizes, emb_dim=8, hidden_dims=[32,32]):\n",
        "        super().__init__()\n",
        "        self.fm1 = nn.ModuleList([nn.Embedding(fs, 1)      for fs in feature_sizes])\n",
        "        self.fm2 = nn.ModuleList([nn.Embedding(fs, emb_dim) for fs in feature_sizes])\n",
        "        all_dims = [len(feature_sizes)*emb_dim] + hidden_dims\n",
        "        self.linears = nn.ModuleList(\n",
        "            nn.Linear(all_dims[i], all_dims[i+1])\n",
        "            for i in range(len(hidden_dims))\n",
        "        )\n",
        "        self.out  = nn.Linear(all_dims[-1], 1)\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, Xi, Xv):\n",
        "        B = Xi.size(0)\n",
        "        # 1st‐order\n",
        "        fm1_terms = []\n",
        "        for i, emb in enumerate(self.fm1):\n",
        "            idx = Xi[:,i,0]                   # [B]\n",
        "            w   = Xv[:,i,0].unsqueeze(1)      # [B,1]\n",
        "            fm1_terms.append(emb(idx)*w)      # [B,1]\n",
        "        fm1 = torch.cat(fm1_terms, dim=1)     # [B,2]\n",
        "\n",
        "        # 2nd‐order\n",
        "        v_terms = []\n",
        "        for i, emb in enumerate(self.fm2):\n",
        "            idx = Xi[:,i,0]\n",
        "            w   = Xv[:,i,0].unsqueeze(1)\n",
        "            v_terms.append(emb(idx)*w)        # [B,emb_dim]\n",
        "        summed    = sum(v_terms)\n",
        "        summed_sq = summed*summed\n",
        "        sq_sum    = sum(v*v for v in v_terms)\n",
        "        fm2       = 0.5*(summed_sq - sq_sum) # [B,emb_dim]\n",
        "\n",
        "        # deep part\n",
        "        x = torch.cat(v_terms, dim=1)        # [B,2*emb_dim]\n",
        "        for lin in self.linears:\n",
        "            x = F.relu(lin(x))\n",
        "        deep_out = self.out(x).squeeze(1)\n",
        "\n",
        "        # combine\n",
        "        return fm1.sum(1) + fm2.sum(1) + deep_out + self.bias  # [B]\n"
      ],
      "metadata": {
        "id": "lAJbrVw5GVjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DeepFM([n_users, n_items], emb_dim=8, hidden_dims=[32,32]).to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "crit  = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "RaLD9JShGYwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 7) TRAIN & VALIDATE ──────────────────────────────────────────────────────\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    tot, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for Xi, Xv, y in loader:\n",
        "            Xi, Xv, y = Xi.to(device), Xv.to(device), y.to(device)\n",
        "            pred = model(Xi, Xv)\n",
        "            tot += crit(pred, y).item()*y.size(0)\n",
        "            n   += y.size(0)\n",
        "    return tot/n\n",
        "\n",
        "for ep in range(1,11):\n",
        "    model.train()\n",
        "    run, n = 0.0, 0\n",
        "    for Xi, Xv, y in train_loader:\n",
        "        Xi, Xv, y = Xi.to(device), Xv.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        pred = model(Xi, Xv)\n",
        "        loss = crit(pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        run += loss.item()*y.size(0)\n",
        "        n   += y.size(0)\n",
        "    print(f\"Epoch {ep} — train_loss: {run/n:.4f}, val_loss: {evaluate(val_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x85MIFuMGbJg",
        "outputId": "0218eb2b-46c7-4416-e502-202c4bb77285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — train_loss: 1.2375, val_loss: 1.0490\n",
            "Epoch 2 — train_loss: 0.8949, val_loss: 0.8118\n",
            "Epoch 3 — train_loss: 0.7816, val_loss: 0.7894\n",
            "Epoch 4 — train_loss: 0.7520, val_loss: 0.7746\n",
            "Epoch 5 — train_loss: 0.7280, val_loss: 0.7628\n",
            "Epoch 6 — train_loss: 0.7062, val_loss: 0.7531\n",
            "Epoch 7 — train_loss: 0.6866, val_loss: 0.7435\n",
            "Epoch 8 — train_loss: 0.6674, val_loss: 0.7343\n",
            "Epoch 9 — train_loss: 0.6497, val_loss: 0.7271\n",
            "Epoch 10 — train_loss: 0.6327, val_loss: 0.7200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def compute_metrics(loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xi, Xv, y in loader:\n",
        "            Xi, Xv = Xi.to(device), Xv.to(device)\n",
        "            logits = model(Xi, Xv)           # [B]\n",
        "            probas = torch.sigmoid(logits)   # [B]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            ps.append(probas.cpu().numpy())\n",
        "    y_true = np.concatenate(ys)\n",
        "    y_pred = np.concatenate(ps)\n",
        "    auc  = roc_auc_score(y_true, y_pred)\n",
        "    pred_labels = (y_pred >= 0.5).astype(int)\n",
        "    acc  = accuracy_score(y_true, pred_labels)\n",
        "    print(f\" AUC={auc:.4f},  Acc={acc:.4f}\")\n",
        "\n",
        "# after training:\n",
        "compute_metrics(train_loader)\n",
        "compute_metrics(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57LhrK0CGs4q",
        "outputId": "2f09ba30-feb7-45e5-b99e-64a23c3e16ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " AUC=0.5892,  Acc=0.8016\n",
            " AUC=0.5321,  Acc=0.7740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# reverse‐lookup from idx back to ASIN\n",
        "idx2item   = {v:k for k,v in item2idx.items()}\n",
        "# lookup from ASIN → title (from your merged df)\n",
        "item2title = df.drop_duplicates(\"asin\").set_index(\"asin\")[\"title\"].to_dict()\n",
        "\n",
        "def recommend_top_k(model, user_raw, k=5):\n",
        "    model.eval()\n",
        "    # 1) get user index\n",
        "    u_idx = user2idx.get(user_raw, 0)\n",
        "    # 2) find items they already rated in train\n",
        "    seen_asins = set(train_df[train_df[\"user_id\"]==user_raw][\"asin\"])\n",
        "    # 3) build candidate ASIN list\n",
        "    candidates = [a for a in items if a not in seen_asins]\n",
        "    N = len(candidates)\n",
        "    if N==0: return []\n",
        "    # 4) build tensors\n",
        "    u_tensor   = torch.LongTensor([u_idx]*N).to(device)\n",
        "    i_tensor   = torch.LongTensor([item2idx[a] for a in candidates]).to(device)\n",
        "    Xi         = torch.stack([u_tensor, i_tensor], dim=1).unsqueeze(2)  # [N,2,1]\n",
        "    Xv         = torch.ones_like(Xi, dtype=torch.float)\n",
        "    # 5) score\n",
        "    with torch.no_grad():\n",
        "        logits  = model(Xi, Xv)               # [N]\n",
        "        probs   = torch.sigmoid(logits).cpu().numpy()\n",
        "    # 6) pick top-k\n",
        "    idxs    = np.argsort(probs)[::-1][:k]\n",
        "    results = []\n",
        "    for i in idxs:\n",
        "        asin  = candidates[i]\n",
        "        title = item2title.get(asin, \"\")\n",
        "        p     = float(probs[i])\n",
        "        results.append((asin, title, p))\n",
        "    return results"
      ],
      "metadata": {
        "id": "7nRUh8fVGrv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = train_df.iloc[0][\"user_id\"]\n",
        "for asin, title, score in recommend_top_k(model, user, k=5):\n",
        "    print(f\"{asin} → {title}  (p={score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slLQ8XUzGxZv",
        "outputId": "102057e8-3003-47d8-8428-2ceef22e10af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B00MIN72JO → Four Stars  (p=1.0000)\n",
            "B00IOTNDDA → BETTER THAN REAL....  (p=1.0000)\n",
            "B00EDN43OE → This chair is cute but not overly comfortable. It is really packed full of fill  (p=1.0000)\n",
            "B0755RJ9C8 → Comes in Handy  (p=1.0000)\n",
            "B0765BTD13 → Does the job!  (p=1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QuSRxzzMLnU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_and_compare(model, user_raw, k=5):\n",
        "    # 1) Grab their past purchases (in training set)\n",
        "    seen_mask = train_df[\"user_id\"] == user_raw\n",
        "    past_asins = train_df.loc[seen_mask, \"asin\"].unique().tolist()\n",
        "    past_titles = [item2title[a] for a in past_asins]\n",
        "\n",
        "    # 2) Get top-k recs\n",
        "    recs = recommend_top_k(model, user_raw, k)\n",
        "\n",
        "    return past_asins, past_titles, recs\n",
        "\n",
        "# Usage for the first user in train_df:\n",
        "user = train_df.iloc[0][\"user_id\"]\n",
        "past_asins, past_titles, recs = recommend_and_compare(model, user, k=5)\n",
        "\n",
        "print(f\"User {user} — past purchases:\")\n",
        "for a, t in zip(past_asins, past_titles):\n",
        "    print(f\"  {a} → {t}\")\n",
        "\n",
        "print(\"\\nTop-5 DeepFM recommendations:\")\n",
        "for asin, title, score in recs:\n",
        "    print(f\"  {asin} → {title}  (p={score:.4f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HltnSZCVLnW9",
        "outputId": "2b1fd52a-9d24-40f7-d8f7-08ce06b2baae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User AF5UYBKAI373BZMFTLUQIYNXX4PA — past purchases:\n",
            "  B075N9Q4KW → When grinding meat it would be easier with a second pair of hands.\n",
            "  B079VW8D2R → Great set, great price!\n",
            "  B00DN6T6LM → Great blanket\n",
            "  B00TFBQBTO → Looks great\n",
            "  B0BCQSP57G → Did not meet my expectation\n",
            "  B00JZX3U8C → Will rust\n",
            "  B084FXW67J → Great\n",
            "  B00E9UNNB0 → Easy to use\n",
            "  B07YFJ1QF1 → Great product\n",
            "  B08TRM4V9J → Easy to use\n",
            "  B000BPILY6 → They melt\n",
            "  B099915KWZ → nice\n",
            "  B08G1STVQK → Great product for the price paid.\n",
            "  B000U9WXEC → Cheap product!!!!\n",
            "  B010TCP3SC → Great product\n",
            "\n",
            "Top-5 DeepFM recommendations:\n",
            "  B00MIN72JO → Four Stars  (p=1.0000)\n",
            "  B00IOTNDDA → BETTER THAN REAL....  (p=1.0000)\n",
            "  B00EDN43OE → This chair is cute but not overly comfortable. It is really packed full of fill  (p=1.0000)\n",
            "  B0755RJ9C8 → Comes in Handy  (p=1.0000)\n",
            "  B0765BTD13 → Does the job!  (p=1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aydHEGmFkbxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Lxgaf0kkbz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/home_reviews_joined_364000.csv\")\n"
      ],
      "metadata": {
        "id": "ahHzxWPEkb18"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfC3nhgYq6ff",
        "outputId": "7859f277-e0ed-4ec6-9199-d11e7ef59a14"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rating', 'review_title', 'text', 'asin', 'parent_asin', 'user_id', 'timestamp', 'verified_purchase', 'main_category', 'product_title', 'average_rating', 'rating_number', 'features', 'description', 'price', 'store', 'categories', 'details', 'label', 'user_idx', 'item_idx']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.columns)\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDHzvOdpkiEn",
        "outputId": "726ed7e3-d785-49b9-a6c5-cf7da36a935b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   rating              review_title  \\\n",
            "0     1.0  So matcha disappointment   \n",
            "1     5.0          Perfect mattress   \n",
            "2     5.0           Great bed frame   \n",
            "3     5.0         Great bar stools!   \n",
            "4     4.0                 It works.   \n",
            "\n",
            "                                                text        asin parent_asin  \\\n",
            "0  I bought this after reading a TON of reviews a...  B08GP9PFWG  B08GP9PFWG   \n",
            "1  OK, we bought this mattress for our guest room...  B0777K9RGX  B0BPBLYF85   \n",
            "2  Husband reports that the frame was easy to ass...  B07GX9RBN7  B0BJZ4Y8K1   \n",
            "3  These stools (we purchased the cherry color) a...  B005EUJ5O8  B079C5FPW8   \n",
            "4  I wanted a small, inexpensive entryway shoe ra...  B002IPG46Y  B0778KV29D   \n",
            "\n",
            "                        user_id      timestamp  verified_purchase  \\\n",
            "0  AGGZ357AO26RQZVRLGU4D4N52DZQ  1644358432328               True   \n",
            "1  AGGZ357AO26RQZVRLGU4D4N52DZQ  1578276993373               True   \n",
            "2  AGGZ357AO26RQZVRLGU4D4N52DZQ  1578276798605               True   \n",
            "3  AGGZ357AO26RQZVRLGU4D4N52DZQ  1460642286000               True   \n",
            "4  AGGZ357AO26RQZVRLGU4D4N52DZQ  1341922513000               True   \n",
            "\n",
            "  main_category                                      product_title  ...  \\\n",
            "0   Amazon Home  FROTH LABS™ Electric Milk Frother For Coffee, ...  ...   \n",
            "1   Amazon Home  Signature Design by Ashley Chime 12 Inch Mediu...  ...   \n",
            "2   Amazon Home  zizin Queen Size Bed Frame Platform Base 14 In...  ...   \n",
            "3   Amazon Home  Crosley Furniture Upholstered Square Seat Bar ...  ...   \n",
            "4   Amazon Home  ClosetMaid 15 Cube Stackable Storage Organizer...  ...   \n",
            "\n",
            "   rating_number                                           features  \\\n",
            "0          509.0  [\"CONSISTENTLY FROTHY, EVERY TIME — Our milk f...   \n",
            "1        49141.0  [\"MEMORY FOAM MATTRESS: For sound sleep you've...   \n",
            "2         1049.0  ['【Heavey Duty】 Bed frame queen is strong with...   \n",
            "3         1151.0  ['24-inch seat height; Perfect height for 36-i...   \n",
            "4        12294.0  ['STACKING SHELF: Hardware included to securel...   \n",
            "\n",
            "                                         description   price  \\\n",
            "0                                                 []   69.99   \n",
            "1  [\"When it comes to your comfort, discover this...  499.99   \n",
            "2                                                 []   79.99   \n",
            "3  ['Redefine your living space, with the Crosley...  101.86   \n",
            "4  [\"Take your storage & organization to the next...   41.98   \n",
            "\n",
            "                        store  \\\n",
            "0                  FROTH LABS   \n",
            "1  Signature Design by Ashley   \n",
            "2                       zizin   \n",
            "3           Crosley Furniture   \n",
            "4                  ClosetMaid   \n",
            "\n",
            "                                          categories  \\\n",
            "0  ['Home & Kitchen', 'Kitchen & Dining', 'Coffee...   \n",
            "1  ['Home & Kitchen', 'Furniture', 'Bedroom Furni...   \n",
            "2  ['Home & Kitchen', 'Furniture', 'Bedroom Furni...   \n",
            "3  ['Home & Kitchen', 'Furniture', 'Game & Recrea...   \n",
            "4  ['Home & Kitchen', 'Storage & Organization', '...   \n",
            "\n",
            "                                             details label  user_idx  item_idx  \n",
            "0  {\"Brand\": \"FROTH LABS\", \"Special Feature\": \"Di...     0         1         1  \n",
            "1  {\"Product Dimensions\": \"84\\\"L x 71\\\"W x 12\\\"Th...     1         1         2  \n",
            "2  {\"Size\": \"Queen\", \"Product Dimensions\": \"82\\\"L...     1         1         3  \n",
            "3  {\"Color\": \"Black\", \"Frame Material\": \"Wood\", \"...     1         1         4  \n",
            "4  {\"Room Type\": \"Bedroom\", \"Number of Shelves\": ...     1         1         5  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Index(['rating', 'review_title', 'text', 'asin', 'parent_asin', 'user_id',\n",
            "       'timestamp', 'verified_purchase', 'main_category', 'product_title',\n",
            "       'average_rating', 'rating_number', 'features', 'description', 'price',\n",
            "       'store', 'categories', 'details', 'label', 'user_idx', 'item_idx'],\n",
            "      dtype='object')\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15430 entries, 0 to 15429\n",
            "Data columns (total 21 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   rating             15430 non-null  float64\n",
            " 1   review_title       15426 non-null  object \n",
            " 2   text               15426 non-null  object \n",
            " 3   asin               15430 non-null  object \n",
            " 4   parent_asin        15430 non-null  object \n",
            " 5   user_id            15430 non-null  object \n",
            " 6   timestamp          15430 non-null  int64  \n",
            " 7   verified_purchase  15430 non-null  bool   \n",
            " 8   main_category      15430 non-null  object \n",
            " 9   product_title      15430 non-null  object \n",
            " 10  average_rating     15430 non-null  float64\n",
            " 11  rating_number      15430 non-null  float64\n",
            " 12  features           15430 non-null  object \n",
            " 13  description        15430 non-null  object \n",
            " 14  price              12159 non-null  float64\n",
            " 15  store              15429 non-null  object \n",
            " 16  categories         15430 non-null  object \n",
            " 17  details            15430 non-null  object \n",
            " 18  label              15430 non-null  int64  \n",
            " 19  user_idx           15430 non-null  int64  \n",
            " 20  item_idx           15430 non-null  int64  \n",
            "dtypes: bool(1), float64(4), int64(4), object(12)\n",
            "memory usage: 2.4+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 2) FILTER & SAMPLE ────────────────────────────────────────────────────────\n",
        "# only users with >5 reviews\n",
        "user_counts = df[\"user_id\"].value_counts()\n",
        "good_users  = user_counts[user_counts > 5].index\n",
        "df = df[df[\"user_id\"].isin(good_users)].copy()\n",
        "\n",
        "# sample 1,000 users (optional)\n",
        "import random\n",
        "chosen = random.sample(good_users.tolist(), 1_000)\n",
        "df = df[df[\"user_id\"].isin(chosen)].reset_index(drop=True)\n",
        "\n",
        "# ─── 3) LABEL & ENCODE ─────────────────────────────────────────────────────────\n",
        "# binary label: rating >= 4 → positive\n",
        "df[\"label\"] = (df[\"rating\"] >= 4).astype(int)\n",
        "\n",
        "# build lookup maps\n",
        "users = df[\"user_id\"].unique().tolist()\n",
        "items = df[\"asin\"   ].unique().tolist()\n",
        "user2idx = {u:i for i,u in enumerate(users, start=1)}\n",
        "item2idx = {a:i for i,a in enumerate(items, start=1)}\n",
        "\n",
        "df[\"user_idx\"] = df[\"user_id\"].map(user2idx).fillna(0).astype(int)\n",
        "df[\"item_idx\"] = df[\"asin\"   ].map(item2idx).fillna(0).astype(int)\n",
        "\n",
        "# ─── 4) SPLIT ─────────────────────────────────────────────────────────────────\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# ─── 5) DATASET ────────────────────────────────────────────────────────────────\n",
        "class FMDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.u = torch.LongTensor(df[\"user_idx\"].values)\n",
        "        self.i = torch.LongTensor(df[\"item_idx\"].values)\n",
        "        self.y = torch.FloatTensor(df[\"label\"].values)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, idx):\n",
        "        Xi = torch.stack([self.u[idx], self.i[idx]]).unsqueeze(1)  # [fields=2,1]\n",
        "        Xv = torch.ones_like(Xi, dtype=torch.float)               # all weights=1\n",
        "        return Xi, Xv, self.y[idx]\n",
        "\n",
        "batch_size    = 512\n",
        "train_loader  = DataLoader(FMDataset(train_df), batch_size, shuffle=True)\n",
        "val_loader    = DataLoader(FMDataset(val_df),   batch_size)\n",
        "\n",
        "n_users = len(user2idx) + 1\n",
        "n_items = len(item2idx) + 1\n",
        "\n",
        "# ─── 6) DeepFM ────────────────────────────────────────────────────────────────\n",
        "class DeepFM(nn.Module):\n",
        "    def __init__(self, feature_sizes, emb_dim=8, hidden_dims=[32,32]):\n",
        "        super().__init__()\n",
        "        self.fm1 = nn.ModuleList([nn.Embedding(fs, 1)      for fs in feature_sizes])\n",
        "        self.fm2 = nn.ModuleList([nn.Embedding(fs, emb_dim) for fs in feature_sizes])\n",
        "        all_dims = [len(feature_sizes)*emb_dim] + hidden_dims\n",
        "        self.linears = nn.ModuleList(\n",
        "            nn.Linear(all_dims[i], all_dims[i+1])\n",
        "            for i in range(len(hidden_dims))\n",
        "        )\n",
        "        self.out  = nn.Linear(all_dims[-1], 1)\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, Xi, Xv):\n",
        "        B = Xi.size(0)\n",
        "        # 1st‐order\n",
        "        fm1_terms = []\n",
        "        for i, emb in enumerate(self.fm1):\n",
        "            idx = Xi[:,i,0]                   # [B]\n",
        "            w   = Xv[:,i,0].unsqueeze(1)      # [B,1]\n",
        "            fm1_terms.append(emb(idx)*w)      # [B,1]\n",
        "        fm1 = torch.cat(fm1_terms, dim=1)     # [B,2]\n",
        "\n",
        "        # 2nd‐order\n",
        "        v_terms = []\n",
        "        for i, emb in enumerate(self.fm2):\n",
        "            idx = Xi[:,i,0]\n",
        "            w   = Xv[:,i,0].unsqueeze(1)\n",
        "            v_terms.append(emb(idx)*w)        # [B,emb_dim]\n",
        "        summed    = sum(v_terms)\n",
        "        summed_sq = summed*summed\n",
        "        sq_sum    = sum(v*v for v in v_terms)\n",
        "        fm2       = 0.5*(summed_sq - sq_sum) # [B,emb_dim]\n",
        "\n",
        "        # deep part\n",
        "        x = torch.cat(v_terms, dim=1)        # [B,2*emb_dim]\n",
        "        for lin in self.linears:\n",
        "            x = F.relu(lin(x))\n",
        "        deep_out = self.out(x).squeeze(1)\n",
        "\n",
        "        # combine\n",
        "        return fm1.sum(1) + fm2.sum(1) + deep_out + self.bias  # [B]\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DeepFM([n_users, n_items], emb_dim=8, hidden_dims=[32,32]).to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "crit  = nn.BCEWithLogitsLoss()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Iyl1-cKwlEBW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 7) TRAIN & VALIDATE ──────────────────────────────────────────────────────\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    tot, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for Xi, Xv, y in loader:\n",
        "            Xi, Xv, y = Xi.to(device), Xv.to(device), y.to(device)\n",
        "            pred = model(Xi, Xv)\n",
        "            tot += crit(pred, y).item()*y.size(0)\n",
        "            n   += y.size(0)\n",
        "    return tot/n\n",
        "\n",
        "for ep in range(1,11):\n",
        "    model.train()\n",
        "    run, n = 0.0, 0\n",
        "    for Xi, Xv, y in train_loader:\n",
        "        Xi, Xv, y = Xi.to(device), Xv.to(device), y.to(device)\n",
        "        opt.zero_grad()\n",
        "        pred = model(Xi, Xv)\n",
        "        loss = crit(pred, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        run += loss.item()*y.size(0)\n",
        "        n   += y.size(0)\n",
        "    print(f\"Epoch {ep} — train_loss: {run/n:.4f}, val_loss: {evaluate(val_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBY7H3lVm3Qo",
        "outputId": "89fd21ae-e04e-45b4-c686-29e6055fd904"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 — train_loss: 1.3902, val_loss: 1.3072\n",
            "Epoch 2 — train_loss: 1.1958, val_loss: 1.1147\n",
            "Epoch 3 — train_loss: 0.9918, val_loss: 0.9232\n",
            "Epoch 4 — train_loss: 0.8429, val_loss: 0.8248\n",
            "Epoch 5 — train_loss: 0.7856, val_loss: 0.7963\n",
            "Epoch 6 — train_loss: 0.7622, val_loss: 0.7865\n",
            "Epoch 7 — train_loss: 0.7430, val_loss: 0.7791\n",
            "Epoch 8 — train_loss: 0.7263, val_loss: 0.7727\n",
            "Epoch 9 — train_loss: 0.7110, val_loss: 0.7662\n",
            "Epoch 10 — train_loss: 0.6960, val_loss: 0.7620\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "def compute_metrics(loader):\n",
        "    model.eval()\n",
        "    ys, ps = [], []\n",
        "    with torch.no_grad():\n",
        "        for Xi, Xv, y in loader:\n",
        "            Xi, Xv = Xi.to(device), Xv.to(device)\n",
        "            logits = model(Xi, Xv)           # [B]\n",
        "            probas = torch.sigmoid(logits)   # [B]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            ps.append(probas.cpu().numpy())\n",
        "    y_true = np.concatenate(ys)\n",
        "    y_pred = np.concatenate(ps)\n",
        "    auc  = roc_auc_score(y_true, y_pred)\n",
        "    pred_labels = (y_pred >= 0.5).astype(int)\n",
        "    acc  = accuracy_score(y_true, pred_labels)\n",
        "    print(f\" AUC={auc:.4f},  Acc={acc:.4f}\")\n",
        "\n",
        "# after training:\n",
        "compute_metrics(train_loader)\n",
        "compute_metrics(val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4PPtaKnnh4F",
        "outputId": "855eaeef-6330-4b75-a6ca-d3353702dc81"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " AUC=0.5767,  Acc=0.7945\n",
            " AUC=0.5090,  Acc=0.7813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Build a lookup from ASIN → product_title\n",
        "item2title = (\n",
        "    train_df\n",
        "      .drop_duplicates(\"asin\")        # one title per ASIN\n",
        "      .set_index(\"asin\")[\"product_title\"]\n",
        "      .to_dict()\n",
        ")\n",
        "\n",
        "# 5) (re)define your recommend_and_compare\n",
        "def recommend_and_compare(model, user_raw, k=5):\n",
        "    # grab all ASINs this user has in *training* data\n",
        "    seen_mask   = train_df[\"user_id\"] == user_raw\n",
        "    past_asins  = train_df.loc[seen_mask, \"asin\"].unique().tolist()\n",
        "    # map to titles (use .get so we don’t KeyError if something’s missing)\n",
        "    past_titles = [ item2title.get(a, \"\") for a in past_asins ]\n",
        "\n",
        "    # get your top-k DeepFM recs\n",
        "    recs = recommend_top_k(model, user_raw, k)\n",
        "\n",
        "    return past_asins, past_titles, recs\n",
        "\n",
        "# 6) Usage example\n",
        "user = train_df.iloc[0][\"user_id\"]\n",
        "past_asins, past_titles, recs = recommend_and_compare(model, user, k=5)\n",
        "\n",
        "print(f\"User {user} — past purchases:\")\n",
        "for a, t in zip(past_asins, past_titles):\n",
        "    print(f\"  {a}  →  {t}\")\n",
        "\n",
        "print(\"\\nTop-5 DeepFM recommendations:\")\n",
        "for asin, title, score in recs:\n",
        "    print(f\"  {asin}  →  {title}  (p={score:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "VP1LxVyHr1WW",
        "outputId": "11230975-365f-48de-f3cc-ab92d2ee28a2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'B001KW0CCI'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-9dc0208f16e3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 6) Usage example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpast_asins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_and_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"User {user} — past purchases:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-9dc0208f16e3>\u001b[0m in \u001b[0;36mrecommend_and_compare\u001b[0;34m(model, user_raw, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# get your top-k DeepFM recs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mrecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommend_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpast_asins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpast_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-1940a0e6d0b4>\u001b[0m in \u001b[0;36mrecommend_top_k\u001b[0;34m(model, user_raw, k)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprobs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtopk\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem2title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-1940a0e6d0b4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprobs\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtopk\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem2title\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'B001KW0CCI'"
          ]
        }
      ]
    }
  ]
}